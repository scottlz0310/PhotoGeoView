#!/usr/bin/env python3
"""
ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆè¡¨ç¤ºä¿®æ­£ - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯

ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã€é•·æ™‚é–“ä½¿ç”¨ã§ã®å®‰å®šæ€§ã€å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ€§èƒ½ã‚’ç¢ºèªã—ã¾ã™ã€‚

è¦ä»¶: 4.1, 4.2, 4.3

Author: Kiro AI Integration System
"""

import gc
import os
import shutil
import sys
import tempfile
import time
import unittest
from datetime import datetime
from pathlib import Path
from typing import Any, Dict

import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.integration.logging_system import LoggerSystem
from src.integration.services.file_discovery_service import FileDiscoveryService
from src.integration.services.memory_aware_file_discovery import (
    MemoryAwareFileDiscovery,
)
from src.integration.services.paginated_file_discovery import PaginatedFileDiscovery


class PerformanceFinalCheckTest(unittest.TestCase):
    """
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

    ãƒ†ã‚¹ãƒˆå¯¾è±¡:
    - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç¢ºèª
    - é•·æ™‚é–“ä½¿ç”¨ã§ã®å®‰å®šæ€§ç¢ºèª
    - å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ€§èƒ½ç¢ºèª
    """

    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # Windowsç’°å¢ƒã§ã®å•é¡Œã‚’å›é¿
        import platform

        if platform.system() == "Windows":
            self.skipTest("Windowsç’°å¢ƒã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")

        self.test_dir = Path(tempfile.mkdtemp())
        self.logger_system = LoggerSystem()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨
        self.process = psutil.Process(os.getpid())
        self.performance_data = []

        # ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ¼ãƒ“ã‚¹
        self.file_discovery_service = FileDiscoveryService(logger_system=self.logger_system)

        self.memory_aware_discovery = MemoryAwareFileDiscovery(max_memory_mb=256, logger_system=self.logger_system)

        self.paginated_discovery = PaginatedFileDiscovery(page_size=100, logger_system=self.logger_system)

    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.test_dir.exists():
            shutil.rmtree(self.test_dir)

        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()

    def _create_large_test_dataset(self, count: int = 1000) -> Path:
        """å¤§é‡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ"""
        large_dir = self.test_dir / f"large_dataset_{count}"
        large_dir.mkdir()

        print(f"   {count}å€‹ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")

        for i in range(count):
            # æ§˜ã€…ãªã‚µã‚¤ã‚ºã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            size_multiplier = (i % 10) + 1
            file_name = f"test_image_{i:04d}.jpg"
            file_path = large_dir / file_name
            file_path.write_bytes(b"test_image_data" * size_multiplier * 100)

        return large_dir

    def _monitor_memory_usage(self) -> Dict[str, float]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–"""
        memory_info = self.process.memory_info()
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,
            "vms_mb": memory_info.vms / 1024 / 1024,
            "percent": self.process.memory_percent(),
        }

    def test_01_memory_leak_detection(self):
        """
        ãƒ†ã‚¹ãƒˆ1: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ

        åŒã˜å‡¦ç†ã‚’ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã—ã¦ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒãªã„ã“ã¨ã‚’ç¢ºèª
        è¦ä»¶: 4.3
        """
        print("\n=== ãƒ†ã‚¹ãƒˆ1: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ ===")

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        test_dir = self._create_large_test_dataset(500)

        # åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        initial_memory = self._monitor_memory_usage()
        print(f"   åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory['rss_mb']:.1f}MB")

        memory_measurements = []

        # 100å›ã®ç¹°ã‚Šè¿”ã—å‡¦ç†
        for iteration in range(100):
            # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºå‡¦ç†
            images = self.file_discovery_service.discover_images(test_dir)

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
            if iteration % 10 == 0:
                current_memory = self._monitor_memory_usage()
                memory_measurements.append(
                    {
                        "iteration": iteration,
                        "memory_mb": current_memory["rss_mb"],
                        "images_found": len(images),
                    }
                )

                if iteration > 0:
                    print(f"   åå¾© {iteration}: {current_memory['rss_mb']:.1f}MB ({len(images)}å€‹ã®ç”»åƒ)")

            # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            if iteration % 20 == 0:
                gc.collect()

        # æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        final_memory = self._monitor_memory_usage()
        memory_increase = final_memory["rss_mb"] - initial_memory["rss_mb"]

        print(f"   æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory['rss_mb']:.1f}MB")
        print(f"   ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡: {memory_increase:.1f}MB")

        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯åˆ¤å®šï¼ˆ50MBä»¥ä¸‹ã®å¢—åŠ ã¯è¨±å®¹ï¼‰
        memory_leak_detected = memory_increase > 50.0

        self.assertFalse(
            memory_leak_detected,
            f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {memory_increase:.1f}MBå¢—åŠ ",
        )

        print(f"âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ{'æˆåŠŸ' if not memory_leak_detected else 'å¤±æ•—'}")

    def test_02_long_term_stability(self):
        """
        ãƒ†ã‚¹ãƒˆ2: é•·æ™‚é–“ä½¿ç”¨å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ

        é•·æ™‚é–“ã®é€£ç¶šä½¿ç”¨ã§ã®å®‰å®šæ€§ã‚’ç¢ºèª
        è¦ä»¶: 4.2, 4.3
        """
        print("\n=== ãƒ†ã‚¹ãƒˆ2: é•·æ™‚é–“ä½¿ç”¨å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ ===")

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        test_dirs = []
        for i in range(5):
            test_dir = self._create_large_test_dataset(200)
            test_dirs.append(test_dir)

        start_time = time.time()
        target_duration = 60  # 60ç§’é–“ã®ãƒ†ã‚¹ãƒˆ

        iteration_count = 0
        error_count = 0
        performance_samples = []

        print(f"   {target_duration}ç§’é–“ã®é€£ç¶šå‡¦ç†ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

        while time.time() - start_time < target_duration:
            iteration_start = time.time()

            try:
                # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
                test_dir = test_dirs[iteration_count % len(test_dirs)]
                images = self.file_discovery_service.discover_images(test_dir)

                iteration_time = time.time() - iteration_start
                memory_usage = self._monitor_memory_usage()

                performance_samples.append(
                    {
                        "iteration": iteration_count,
                        "duration": iteration_time,
                        "images_found": len(images),
                        "memory_mb": memory_usage["rss_mb"],
                        "timestamp": time.time(),
                    }
                )

                iteration_count += 1

                # é€²æ—è¡¨ç¤º
                if iteration_count % 10 == 0:
                    elapsed = time.time() - start_time
                    print(
                        f"   {elapsed:.0f}ç§’çµŒé: {iteration_count}å›å‡¦ç†å®Œäº† "
                        f"(å¹³å‡ {iteration_time:.3f}ç§’/å›, {memory_usage['rss_mb']:.1f}MB)"
                    )

            except Exception as e:
                error_count += 1
                print(f"   ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (åå¾© {iteration_count}): {e}")

                # ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã‚‹å ´åˆã¯ãƒ†ã‚¹ãƒˆå¤±æ•—
                if error_count > iteration_count * 0.1:  # 10%ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ç‡
                    self.fail(f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {error_count}/{iteration_count}")

            # CPUè² è·è»½æ¸›ã®ãŸã‚ã®çŸ­ã„ä¼‘æ†©
            time.sleep(0.01)

        total_duration = time.time() - start_time

        # çµ±è¨ˆè¨ˆç®—
        if performance_samples:
            avg_duration = sum(s["duration"] for s in performance_samples) / len(performance_samples)
            max_duration = max(s["duration"] for s in performance_samples)
            avg_memory = sum(s["memory_mb"] for s in performance_samples) / len(performance_samples)
            max_memory = max(s["memory_mb"] for s in performance_samples)
        else:
            avg_duration = max_duration = avg_memory = max_memory = 0

        print(f"   ç·å‡¦ç†æ™‚é–“: {total_duration:.1f}ç§’")
        print(f"   ç·åå¾©å›æ•°: {iteration_count}å›")
        print(f"   ã‚¨ãƒ©ãƒ¼å›æ•°: {error_count}å›")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_duration:.3f}ç§’")
        print(f"   æœ€å¤§å‡¦ç†æ™‚é–“: {max_duration:.3f}ç§’")
        print(f"   å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {avg_memory:.1f}MB")
        print(f"   æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {max_memory:.1f}MB")

        # å®‰å®šæ€§åˆ¤å®š
        error_rate = error_count / iteration_count if iteration_count > 0 else 1.0
        stability_ok = error_rate < 0.05 and max_duration < 10.0  # ã‚¨ãƒ©ãƒ¼ç‡5%æœªæº€ã€æœ€å¤§å‡¦ç†æ™‚é–“10ç§’æœªæº€

        self.assertTrue(
            stability_ok,
            f"é•·æ™‚é–“ä½¿ç”¨å®‰å®šæ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™: ã‚¨ãƒ©ãƒ¼ç‡{error_rate:.1%}, æœ€å¤§å‡¦ç†æ™‚é–“{max_duration:.3f}ç§’",
        )

        print(f"âœ… é•·æ™‚é–“ä½¿ç”¨å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ{'æˆåŠŸ' if stability_ok else 'å¤±æ•—'}")

    def test_03_large_file_performance(self):
        """
        ãƒ†ã‚¹ãƒˆ3: å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ

        å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ€§èƒ½ã‚’ç¢ºèª
        è¦ä»¶: 4.1, 4.2
        """
        print("\n=== ãƒ†ã‚¹ãƒˆ3: å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ ===")

        # ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆ
        test_sizes = [1000, 2000, 5000]
        performance_results = []

        for size in test_sizes:
            print(f"   {size}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆ...")

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
            large_dir = self._create_large_test_dataset(size)

            # é€šå¸¸ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            initial_memory = self._monitor_memory_usage()

            images = self.file_discovery_service.discover_images(large_dir)

            normal_duration = time.time() - start_time
            normal_memory = self._monitor_memory_usage()

            # æ®µéšçš„èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            paginated_memory = self._monitor_memory_usage()

            paginated_images = []
            batch_count = 0

            self.paginated_discovery.set_folder(large_dir)
            while self.paginated_discovery.has_more_files():
                batch = self.paginated_discovery.get_next_batch()
                paginated_images.extend(batch)
                batch_count += 1

                # ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢
                if batch_count > 100:
                    break

            paginated_duration = time.time() - start_time
            paginated_final_memory = self._monitor_memory_usage()

            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªæ¤œå‡ºãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            memory_aware_initial = self._monitor_memory_usage()

            memory_aware_images = self.memory_aware_discovery.discover_images(large_dir)

            memory_aware_duration = time.time() - start_time
            memory_aware_final = self._monitor_memory_usage()

            result = {
                "file_count": size,
                "normal": {
                    "duration": normal_duration,
                    "images_found": len(images),
                    "memory_increase": normal_memory["rss_mb"] - initial_memory["rss_mb"],
                },
                "paginated": {
                    "duration": paginated_duration,
                    "images_found": len(paginated_images),
                    "batch_count": batch_count,
                    "memory_increase": paginated_final_memory["rss_mb"] - paginated_memory["rss_mb"],
                },
                "memory_aware": {
                    "duration": memory_aware_duration,
                    "images_found": len(memory_aware_images),
                    "memory_increase": memory_aware_final["rss_mb"] - memory_aware_initial["rss_mb"],
                },
            }

            performance_results.append(result)

            print(
                f"     é€šå¸¸æ¤œå‡º: {normal_duration:.3f}ç§’, {len(images)}å€‹, "
                f"ãƒ¡ãƒ¢ãƒªå¢—åŠ  {result['normal']['memory_increase']:.1f}MB"
            )
            print(
                f"     æ®µéšçš„èª­ã¿è¾¼ã¿: {paginated_duration:.3f}ç§’, {len(paginated_images)}å€‹, "
                f"{batch_count}ãƒãƒƒãƒ, ãƒ¡ãƒ¢ãƒªå¢—åŠ  {result['paginated']['memory_increase']:.1f}MB"
            )
            print(
                f"     ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„: {memory_aware_duration:.3f}ç§’, {len(memory_aware_images)}å€‹, "
                f"ãƒ¡ãƒ¢ãƒªå¢—åŠ  {result['memory_aware']['memory_increase']:.1f}MB"
            )

        # æ€§èƒ½è¦ä»¶ã®ç¢ºèª
        performance_ok = True
        for result in performance_results:
            # 5000ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚30ç§’ä»¥å†…ã§å‡¦ç†å®Œäº†
            if result["file_count"] == 5000 and result["normal"]["duration"] > 30.0:
                performance_ok = False
                print(f"âŒ 5000ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {result['normal']['duration']:.3f}ç§’")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ200MBä»¥ä¸‹
            if result["normal"]["memory_increase"] > 200.0:
                performance_ok = False
                print(f"âŒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè¦ä»¶ã‚’è¶…é: {result['normal']['memory_increase']:.1f}MB")

        self.assertTrue(performance_ok, "å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“")

        print(f"âœ… å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ{'æˆåŠŸ' if performance_ok else 'å¤±æ•—'}")

        return performance_results

    def generate_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        return {
            "test_suite": "PerformanceFinalCheckTest",
            "timestamp": datetime.now().isoformat(),
            "performance_data": self.performance_data,
            "system_info": {
                "cpu_count": psutil.cpu_count(),
                "memory_total_gb": psutil.virtual_memory().total / 1024 / 1024 / 1024,
                "python_version": sys.version,
            },
        }


def run_performance_final_check():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
    print("=" * 80)
    print("ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆè¡¨ç¤ºä¿®æ­£ - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯")
    print("=" * 80)

    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ
    suite = unittest.TestLoader().loadTestsFromTestCase(PerformanceFinalCheckTest)
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    print("\n" + "=" * 80)
    print("ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ãƒã‚§ãƒƒã‚¯çµæœ")
    print("=" * 80)
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±æ•—: {len(result.failures)}")
    print(f"ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")

    if result.failures:
        print("\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")

    if result.errors:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")

    success = result.wasSuccessful()
    print(f"\nğŸ† ç·åˆçµæœ: {'âœ… å…¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã‚¯ãƒªã‚¢' if success else 'âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶æœªé”'}")
    print("=" * 80)

    return success


if __name__ == "__main__":
    success = run_performance_final_check()
    exit(0 if success else 1)
