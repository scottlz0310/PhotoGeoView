#!/usr/bin/env python3
"""
Enhanced GitHub Actions AI Analyzer

GitHub Actions AI Analyzerãƒªãƒã‚¸ãƒˆãƒªç”¨ã«æ‹¡å¼µã•ã‚ŒãŸAIè§£æãƒ„ãƒ¼ãƒ«
è‡ªå‹•çš„ãªãƒ†ã‚¹ãƒˆå“è³ªå‘ä¸Šã¨ç¶™ç¶šçš„ãªæ”¹å–„ã‚’æ”¯æ´ã—ã¾ã™ã€‚
"""

import json
import logging
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("enhanced_github_actions_ai_analyzer")


class EnhancedGitHubActionsAnalyzer:
    """æ‹¡å¼µã•ã‚ŒãŸGitHub Actions AIè§£æã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.analysis_results = {}
        self.patterns = {
            "error": r"ERROR|FAILED|FAILURE|exit code 1|Process completed with exit code 1",
            "warning": r"WARNING|WARN|warning",
            "timeout": r"timeout|TIMEOUT|timed out",
            "windows_specific": r"Windows|windows|WIN",
            "test_failure": r"test.*failed|FAILED.*test|pytest.*failed",
            "import_error": r"ImportError|ModuleNotFoundError|No module named",
            "permission_error": r"PermissionError|permission denied",
            "memory_error": r"MemoryError|out of memory|OOM",
            "coverage_error": r"coverage.*failed|Codecov.*failed",
            "qt_error": r"Qt|PyQt|QT_QPA_PLATFORM",
            "pytest_error": r"pytest.*error|collected.*error",
            "dependency_error": r"pip.*error|npm.*error|yarn.*error",
            "build_error": r"build.*failed|compilation.*error",
            "network_error": r"timeout|connection.*failed|network.*error",
            "security_error": r"security.*vulnerability|CVE|vulnerability",
            "performance_issue": r"performance.*issue|slow|timeout",
            "quality_issue": r"code.*quality|style.*issue|lint.*error"
        }

        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.quality_metrics = {
            "test_coverage": 0.0,
            "build_success_rate": 0.0,
            "error_frequency": 0.0,
            "warning_frequency": 0.0,
            "performance_score": 0.0
        }

    def analyze_ci_report(self, report_path: Path) -> Dict[str, Any]:
        """CIãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æ"""
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                report = json.load(f)

            analysis = {
                "file": str(report_path),
                "timestamp": report.get("timestamp", ""),
                "overall_status": report.get("overall_status", "UNKNOWN"),
                "total_duration": report.get("total_duration", 0),
                "issues": [],
                "recommendations": [],
                "quality_score": 0.0
            }

            # ãƒã‚§ãƒƒã‚¯çµæœã‚’è§£æ
            checks = report.get("checks", {})
            total_checks = len(checks)
            passed_checks = 0

            for check_name, check_data in checks.items():
                status = check_data.get("status", "unknown")
                message = check_data.get("message", "")
                duration = check_data.get("duration", 0)

                if status == "pass":
                    passed_checks += 1
                elif status == "warn" or status == "fail":
                    issue = {
                        "check": check_name,
                        "status": status,
                        "message": message,
                        "duration": duration
                    }
                    analysis["issues"].append(issue)

                    # æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
                    recommendation = self._generate_recommendation(check_name, status, message)
                    if recommendation:
                        analysis["recommendations"].append(recommendation)

            # å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            if total_checks > 0:
                analysis["quality_score"] = (passed_checks / total_checks) * 100

            return analysis

        except Exception as e:
            logger.error(f"CIãƒ¬ãƒãƒ¼ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def analyze_log_file(self, log_path: Path) -> Dict[str, Any]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                content = f.read()

            analysis = {
                "file": str(log_path),
                "patterns_found": {},
                "issues": [],
                "recommendations": [],
                "quality_metrics": {}
            }

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            for pattern_name, pattern in self.patterns.items():
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    analysis["patterns_found"][pattern_name] = {
                        "count": len(matches),
                        "examples": matches[:5]  # æœ€åˆã®5ã¤ã®ä¾‹
                    }

            # å•é¡Œã®ç‰¹å®š
            if analysis["patterns_found"].get("error"):
                analysis["issues"].append({
                    "type": "error",
                    "description": "ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ",
                    "count": analysis["patterns_found"]["error"]["count"]
                })

            if analysis["patterns_found"].get("windows_specific"):
                analysis["issues"].append({
                    "type": "windows_specific",
                    "description": "Windowså›ºæœ‰ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ",
                    "count": analysis["patterns_found"]["windows_specific"]["count"]
                })

            if analysis["patterns_found"].get("test_failure"):
                analysis["issues"].append({
                    "type": "test_failure",
                    "description": "ãƒ†ã‚¹ãƒˆå¤±æ•—ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ",
                    "count": analysis["patterns_found"]["test_failure"]["count"]
                })

            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
            total_lines = len(content.split('\n'))
            error_count = analysis["patterns_found"].get("error", {}).get("count", 0)
            warning_count = analysis["patterns_found"].get("warning", {}).get("count", 0)

            analysis["quality_metrics"] = {
                "error_frequency": error_count / max(total_lines, 1) * 1000,  # 1000è¡Œã‚ãŸã‚Š
                "warning_frequency": warning_count / max(total_lines, 1) * 1000,
                "total_issues": error_count + warning_count,
                "issue_density": (error_count + warning_count) / max(total_lines, 1)
            }

            # æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
            analysis["recommendations"] = self._generate_log_recommendations(analysis["patterns_found"])

            return analysis

        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _generate_recommendation(self, check_name: str, status: str, message: str) -> Optional[str]:
        """ãƒã‚§ãƒƒã‚¯çµæœã«åŸºã¥ãæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        recommendations = {
            "ãƒ†ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯": {
                "warn": "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†ã‚¨ãƒ©ãƒ¼ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚pytestè¨­å®šã‚’ç¢ºèªã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ§‹é€ ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚",
                "fail": "ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆç’°å¢ƒã®è¨­å®šã¨ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            },
            "æ§‹æ–‡ãƒã‚§ãƒƒã‚¯": {
                "warn": "æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã®æ§‹æ–‡ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚",
                "fail": "é‡å¤§ãªæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚"
            },
            "ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯": {
                "warn": "ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ä¾å­˜é–¢ä¿‚ã¨ãƒ‘ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "fail": "é‡è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            },
            "ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯": {
                "warn": "ä¾å­˜é–¢ä¿‚ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚requirements.txtã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "fail": "ä¾å­˜é–¢ä¿‚ã®è§£æ±ºã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            },
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ": {
                "warn": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "fail": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãŒä¸æ­£ã§ã™ã€‚åŸºæœ¬çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"
            }
        }

        return recommendations.get(check_name, {}).get(status)

    def _generate_log_recommendations(self, patterns_found: Dict) -> List[str]:
        """ãƒ­ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        recommendations = []

        if patterns_found.get("error"):
            recommendations.append("ã‚¨ãƒ©ãƒ¼ãŒå¤šæ•°æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ­ã‚°ã®è©³ç´°ã‚’ç¢ºèªã—ã€æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("windows_specific"):
            recommendations.append("Windowså›ºæœ‰ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚Windowsç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆè¨­å®šã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("test_failure"):
            recommendations.append("ãƒ†ã‚¹ãƒˆå¤±æ•—ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã¨ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("import_error"):
            recommendations.append("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ãƒ‘ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("permission_error"):
            recommendations.append("æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã¨ã‚¢ã‚¯ã‚»ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("memory_error"):
            recommendations.append("ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("coverage_error"):
            recommendations.append("ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®šã¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("qt_error"):
            recommendations.append("Qté–¢é€£ã®ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚Qtç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("dependency_error"):
            recommendations.append("ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®è¨­å®šã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("build_error"):
            recommendations.append("ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ“ãƒ«ãƒ‰è¨­å®šã¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("network_error"):
            recommendations.append("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã¨ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("security_error"):
            recommendations.append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã—ã€è„†å¼±æ€§ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("performance_issue"):
            recommendations.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®æœ€é©åŒ–ã¨ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        if patterns_found.get("quality_issue"):
            recommendations.append("ã‚³ãƒ¼ãƒ‰å“è³ªå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°ã¨ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        return recommendations

    def analyze_multiple_reports(self, reports_dir: Path) -> Dict[str, Any]:
        """è¤‡æ•°ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æ"""
        analysis = {
            "total_reports": 0,
            "successful_reports": 0,
            "failed_reports": 0,
            "warned_reports": 0,
            "trends": {},
            "common_issues": [],
            "recommendations": [],
            "quality_trends": [],
            "overall_quality_score": 0.0
        }

        # JSONãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        json_files = list(reports_dir.glob("ci_report_*.json"))
        analysis["total_reports"] = len(json_files)

        status_counts = {"pass": 0, "warn": 0, "fail": 0}
        all_issues = []
        all_recommendations = []
        quality_scores = []

        for json_file in sorted(json_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]:  # æœ€æ–°10ä»¶
            report_analysis = self.analyze_ci_report(json_file)

            if "error" not in report_analysis:
                status = report_analysis.get("overall_status", "unknown")
                status_counts[status] = status_counts.get(status, 0) + 1

                all_issues.extend(report_analysis.get("issues", []))
                all_recommendations.extend(report_analysis.get("recommendations", []))

                quality_score = report_analysis.get("quality_score", 0.0)
                quality_scores.append(quality_score)

                # è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›
                logger.info(f"è§£æå®Œäº†: {json_file.name} - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status} - å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.1f}")
                if report_analysis.get("issues"):
                    logger.info(f"  å•é¡Œ: {len(report_analysis['issues'])}ä»¶")

        analysis["successful_reports"] = status_counts.get("pass", 0)
        analysis["warned_reports"] = status_counts.get("WARNING", 0)
        analysis["failed_reports"] = status_counts.get("fail", 0)

        # å“è³ªã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        if quality_scores:
            analysis["overall_quality_score"] = sum(quality_scores) / len(quality_scores)

        # å…±é€šã®å•é¡Œã‚’ç‰¹å®š
        issue_types = {}
        for issue in all_issues:
            issue_type = issue.get("check", "unknown")
            issue_types[issue_type] = issue_types.get(issue_type, 0) + 1

        analysis["common_issues"] = [
            {"type": issue_type, "count": count}
            for issue_type, count in sorted(issue_types.items(), key=lambda x: x[1], reverse=True)
        ]

        # æ”¹å–„ææ¡ˆã‚’çµ±åˆ
        analysis["recommendations"] = list(set(all_recommendations))

        return analysis

    def generate_enhanced_report(self, analysis_results: Dict[str, Any]) -> str:
        """æ‹¡å¼µã•ã‚ŒãŸè§£æçµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§å‡ºåŠ›"""
        report = []
        report.append("# Enhanced GitHub Actions AI è§£æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # æ¦‚è¦
        report.append("## ğŸ“Š æ¦‚è¦")
        report.append(f"- ç·ãƒ¬ãƒãƒ¼ãƒˆæ•°: {analysis_results.get('total_reports', 0)}")
        report.append(f"- æˆåŠŸ: {analysis_results.get('successful_reports', 0)}")
        report.append(f"- è­¦å‘Š: {analysis_results.get('warned_reports', 0)}")
        report.append(f"- å¤±æ•—: {analysis_results.get('failed_reports', 0)}")
        report.append(f"- ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {analysis_results.get('overall_quality_score', 0.0):.1f}%")
        report.append("")

        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if analysis_results.get("overall_quality_score", 0) > 0:
            report.append("## ğŸ¯ å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹")
            quality_score = analysis_results.get("overall_quality_score", 0.0)
            if quality_score >= 90:
                report.append(f"- **ç·åˆå“è³ª**: ğŸŸ¢ å„ªç§€ ({quality_score:.1f}%)")
            elif quality_score >= 70:
                report.append(f"- **ç·åˆå“è³ª**: ğŸŸ¡ è‰¯å¥½ ({quality_score:.1f}%)")
            else:
                report.append(f"- **ç·åˆå“è³ª**: ğŸ”´ è¦æ”¹å–„ ({quality_score:.1f}%)")
            report.append("")

        # å…±é€šã®å•é¡Œ
        if analysis_results.get("common_issues"):
            report.append("## ğŸš¨ å…±é€šã®å•é¡Œ")
            for issue in analysis_results["common_issues"]:
                report.append(f"- **{issue['type']}**: {issue['count']}å›ç™ºç”Ÿ")
            report.append("")

        # æ”¹å–„ææ¡ˆ
        if analysis_results.get("recommendations"):
            report.append("## ğŸ’¡ æ”¹å–„ææ¡ˆ")
            for i, recommendation in enumerate(analysis_results["recommendations"], 1):
                report.append(f"{i}. {recommendation}")
            report.append("")

        # ãƒ­ã‚°è§£æçµæœ
        if analysis_results.get("log_analysis"):
            log_analysis = analysis_results["log_analysis"]
            report.append("## ğŸ“‹ CIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°è§£æ")

            if log_analysis.get("patterns_found"):
                report.append("### æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³")
                for pattern_name, pattern_data in log_analysis["patterns_found"].items():
                    count = pattern_data.get("count", 0)
                    report.append(f"- **{pattern_name}**: {count}å›")
                report.append("")

            if log_analysis.get("issues"):
                report.append("### æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
                for issue in log_analysis["issues"]:
                    report.append(f"- **{issue['type']}**: {issue['description']} ({issue['count']}å›)")
                report.append("")

            if log_analysis.get("quality_metrics"):
                report.append("### å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹")
                metrics = log_analysis["quality_metrics"]
                report.append(f"- ã‚¨ãƒ©ãƒ¼é »åº¦: {metrics.get('error_frequency', 0):.2f} (1000è¡Œã‚ãŸã‚Š)")
                report.append(f"- è­¦å‘Šé »åº¦: {metrics.get('warning_frequency', 0):.2f} (1000è¡Œã‚ãŸã‚Š)")
                report.append(f"- ç·å•é¡Œæ•°: {metrics.get('total_issues', 0)}")
                report.append(f"- å•é¡Œå¯†åº¦: {metrics.get('issue_density', 0):.4f}")
                report.append("")

            if log_analysis.get("recommendations"):
                report.append("### ãƒ­ã‚°è§£æã«ã‚ˆã‚‹æ”¹å–„ææ¡ˆ")
                for i, recommendation in enumerate(log_analysis["recommendations"], 1):
                    report.append(f"{i}. {recommendation}")
                report.append("")

        # è‡ªå‹•æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        report.append("## ğŸ¤– è‡ªå‹•æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        report.append("ä»¥ä¸‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼š")
        report.append("")
        report.append("1. **ãƒ†ã‚¹ãƒˆå“è³ªå‘ä¸Š**: å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è‡ªå‹•ä¿®æ­£ææ¡ˆ")
        report.append("2. **ä¾å­˜é–¢ä¿‚æœ€é©åŒ–**: å¤ã„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è‡ªå‹•æ›´æ–°")
        report.append("3. **ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„**: ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•ä¿®æ­£")
        report.append("4. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®è‡ªå‹•ç‰¹å®šã¨ä¿®æ­£")
        report.append("5. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–**: è„†å¼±æ€§ã®è‡ªå‹•æ¤œå‡ºã¨ä¿®æ­£")
        report.append("")

        return "\n".join(report)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    analyzer = EnhancedGitHubActionsAnalyzer()

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    reports_dir = Path("reports")

    if not reports_dir.exists():
        logger.error("reportsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

    # è¤‡æ•°ãƒ¬ãƒãƒ¼ãƒˆã®è§£æ
    logger.info("Enhanced GitHub Actionsãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æä¸­...")
    analysis_results = analyzer.analyze_multiple_reports(reports_dir)

    # CIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®è§£æ
    logs_dir = Path("logs")
    if logs_dir.exists():
        logger.info("CIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’è§£æä¸­...")
        ci_log_file = logs_dir / "ci-simulation.log"
        if ci_log_file.exists():
            log_analysis = analyzer.analyze_log_file(ci_log_file)
            analysis_results["log_analysis"] = log_analysis

    # æ‹¡å¼µãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = analyzer.generate_enhanced_report(analysis_results)

    # çµæœã‚’å‡ºåŠ›
    print(report)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = reports_dir / f"enhanced_ai_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    logger.info(f"æ‹¡å¼µè§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")


if __name__ == "__main__":
    main()
